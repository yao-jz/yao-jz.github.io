---
title: "Workshop of Multimodal Machine Learning + MoE, Tsinghua University"
collection: research
type: 'Workshop'
permalink: /research/2022-06-01-zhouworkshop
date: 2022-06-01
year: 2022
---

##

The main topic of this workshop is Multimodal Machine Learning. At the same time, inspired by the [LIMoE](https://ai.googleblog.com/2022/06/limoe-learning-multiple-modalities-with.html) proposed by Google recently, I am quite interested in the combination of Mixture of Experts architecture and Multimodal Information. After my literature research, I wrote a research proposal and designed experiments for the Multitask Multimodal Mixture of Experts approach.

### Multimodal Machine Learning

### MMMoE: Advancing Multimodal Mixture-of-Experts Architecture to Power Next-Generation Multimodal Paradigm
